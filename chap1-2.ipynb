{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-2 BeautifulSoup로 스크레이핑하기\n",
    "\"BeautifulSoup\"란 파이썬으로 스케레이핑을 할 수 있게 해주는 편리한 라이브러리임.\n",
    "### 이 장에서 배울 내용\n",
    "- 스크레이핑\n",
    "- BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BeautifulSuop로 스크레이핑하기\n",
    "\n",
    "* 스크레이핑이란 웹 사이트에서 데이터를 추출하고, 원하는 정보를 추출하는 것을 의미\n",
    "* \"BeautifulSoup\"란 파이썬으로 스크레이핑할 때 사용되는 라이브러리로서 HTML/XML에서 정보를 추출할 수 있도록 도와줌. 그러나 다운로드 기능은 없음.\n",
    "* 파이썬 라이브러리는 pip 명령어를 이용해 설치 가능. Python Package Index(PyPI)에 있는 패키지 명령어를 한줄로 설치 가능  \n",
    "URL (http://pypi.python.org/pypi)\n",
    "    + $pip install beautifulsoup4 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beautifulsoup 기본 사용\n",
    "다음은 Beautifulsoup를 이용하여 웹사이트로부터 HTML을 가져와 문자열로 만들어 이용하는 예제임\n",
    "* h1 태그를 접근하기 위해 html-body-h1 구조를 사용하여 soup.html.body.h1 이런식으로 이용하게 됨.\n",
    "* p 태그는 두개가 있어 soup.html.body.p 한 후 next_sibling을 두번 이용하여 다음 p를 추출. 한번만 하면 그 다음 공백이 추출됨.\n",
    "* HTML 태그가 복잡한 경우 이런 방식으로 계속 진행하기는 적합하지 않음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h1 = 스크레이핑이란?\n",
      "p  = 웹 페이지를 분석하는 것\n",
      "p  = 원하는 부분을 추출하는 것\n"
     ]
    }
   ],
   "source": [
    "# 라이브러리 읽어 들이기 --- (※1)\n",
    "from bs4 import BeautifulSoup\n",
    "# 분석하고 싶은 HTML --- (※2)\n",
    "html = \"\"\"\n",
    "<html><body>\n",
    "  <h1>스크레이핑이란?</h1>\n",
    "  <p>웹 페이지를 분석하는 것</p>\n",
    "  <p>원하는 부분을 추출하는 것</p>\n",
    "</body></html>\n",
    "\"\"\"\n",
    "# HTML 분석하기 --- (※3)\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "# 원하는 부분 추출하기 --- (※4)\n",
    "h1 = soup.html.body.h1\n",
    "p1 = soup.html.body.p\n",
    "p2 = p1.next_sibling.next_sibling\n",
    "# 요소의 글자 출력하기 --- (※5)\n",
    "print(\"h1 = \" + h1.string)\n",
    "print(\"p  = \" + p1.string)\n",
    "print(\"p  = \" + p2.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### id로 요소를 찾는 방법\n",
    "BeautifulSoup는 루트부터 하나하나 요소를 찾는 방법 말고도 find()라는 메소드를 제공함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>스크레이핑이란?</h1>\n",
      "#title=스크레이핑이란?\n",
      "#body=웹 페이지를 분석하는 것\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "html = \"\"\"\n",
    "<html><title>hello</title>\n",
    "<body>\n",
    "  <h1>스크레이핑이란?</h1>\n",
    "  <p>웹 페이지를 분석하는 것</p>\n",
    "  <p>원하는 부분을 추출하는 것</p>\n",
    "</body></html>\n",
    "\"\"\"\n",
    "# HTML 분석하기 --- (※1)\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "# find() 메서드로 원하는 부분 추출하기 --- (※2)\n",
    "title = soup.find(\"h1\")\n",
    "body  = soup.find(\"p\")\n",
    "print(title)\n",
    "# 텍스트 부분 출력하기\n",
    "print(\"#title=\" + title.string)\n",
    "print(\"#body=\"  + body.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 여러 개의 요소 추출하기 - find_all() 메서드\n",
    "여러개의 태그를 한번에 추출하고자 할때 사용함. 다음의 예제에서는 여러개의 <a> 태그를 추출하는 법을 보여주고 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naver > http://www.naver.com\n",
      "daum > http://www.daum.net\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "html = \"\"\"\n",
    "<html><body>\n",
    "  <ul>\n",
    "    <li><a href=\"http://www.naver.com\">naver</a></li>\n",
    "    <li><a href=\"http://www.daum.net\">daum</a></li>\n",
    "  </ul>\n",
    "</body></html>\n",
    "\"\"\"\n",
    "# HTML 분석하기 --- (※1)\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "# find_all() 메서드로 추출하기 --- (※2)\n",
    "links = soup.find_all(\"a\")\n",
    "# 링크 목록 출력하기 --- (※3)\n",
    "for a in links:\n",
    "    href = a.attrs['href'] # href의 속성에 있는 속성값을 추출\n",
    "    text = a.string \n",
    "    print(text, \">\", href)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### urlopen()과 BeautifulSoup 조합하기\n",
    "* URL을 이용하여 웹으로부터 데이터를 읽어들여 BeautifulSoup으로 원하는 데이터를 추출\n",
    "* 기상청 RSS에서 특정 내용을 추출하는 예제\n",
    "* 기상청 RSS에서 XML 데이터를 추출하고 XML 내용을 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기상청 육상 중기예보\n",
      "기압골의 영향으로 20일은 전국에 비가 오겠고, 서울.경기도와 강원도는 21일까지 이어지겠습니다.<br />그 밖의 날은 고기압의 영향으로 대체로 맑은 날이 많겠습니다.<br />기온은 평년(최저기온: 10~19℃, 최고기온: 22~27℃)과 비슷하겠습니다.<br />강수량은 평년(2~8mm)보다 많겠습니다.\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as req\n",
    "url = \"http://www.kma.go.kr/weather/forecast/mid-term-rss3.jsp\"\n",
    "# urlopen()으로 데이터 가져오기 --- (※1)\n",
    "res = req.urlopen(url)\n",
    "# BeautifulSoup으로 분석하기 --- (※2)\n",
    "soup = BeautifulSoup(res, \"html.parser\")\n",
    "# 원하는 데이터 추출하기 --- (※3)\n",
    "title = soup.find(\"title\").string\n",
    "wf = soup.find(\"wf\").string\n",
    "print(title)\n",
    "print(wf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSS 선택자 사용하기\n",
    "\n",
    "| 메서드 | 설명|\n",
    "|:---:|:---:|\n",
    "| soup.select_one(선택자)| CSS 선택자로 요소 하나를 추출합니다.|\n",
    "| soup.select(선택자) | CSS 선택자로 요소 여러 개를 리스트를 추출합니다. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* HTML 에서 &lt;h1&gt; 태그와 &lt;li&gt; 태그를 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h1 = 위키북스 도서\n",
      "li = 유니티 게임 이펙트 입문\n",
      "li = 스위프트로 시작하는 아이폰 앱 개발 교과서\n",
      "li = 모던 웹사이트 디자인의 정석\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "# 분석 대상 HTML --- (※1)\n",
    "html = \"\"\"\n",
    "<html><body>\n",
    "<div id=\"meigen\">\n",
    "  <h1>위키북스 도서</h1>\n",
    "  <ul class=\"items\">\n",
    "    <li>유니티 게임 이펙트 입문</li>\n",
    "    <li>스위프트로 시작하는 아이폰 앱 개발 교과서</li>\n",
    "    <li>모던 웹사이트 디자인의 정석</li>\n",
    "  </ul>\n",
    "</div>\n",
    "</body></html>\n",
    "\"\"\"\n",
    "# HTML 분석하기 --- (※2)\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "# 필요한 부분을 CSS 쿼리로 추출하기\n",
    "# 타이틀 부분 추출하기 --- (※3)\n",
    "h1 = soup.select_one(\"div#meigen > h1\").string\n",
    "print(\"h1 =\", h1)\n",
    "# 목록 부분 추출하기 --- (※4)\n",
    "li_list = soup.select(\"div#meigen > ul.items > li\")\n",
    "for li in li_list:\n",
    "  print(\"li =\", li.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 네이버 금융에서 환율 정보 추출하기\n",
    "* 실제 웹사이트 스크레이핑 해보기\n",
    "* 다양한 금융 정보가 공개돼 있는 \"네이버 금융\"에서 원/달러 환율 정보를 추출해보자!\n",
    "* 네이버 금융의 시장 지표 페이지 <http://info.finance.naver.com/marketindex>\n",
    "* 다음은 원/달러 환율 정보를 추출하는 프로그램임."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usd/krw = 1,126.50\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as req\n",
    "# HTML 가져오기\n",
    "url = \"http://info.finance.naver.com/marketindex/\"\n",
    "res = req.urlopen(url)\n",
    "# HTML 분석하기\n",
    "soup = BeautifulSoup(res, \"html.parser\")\n",
    "# 원하는 데이터 추출하기 --- (※1)\n",
    "price = soup.select_one(\"div.head_info > span.value\").string\n",
    "print(\"usd/krw =\", price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
